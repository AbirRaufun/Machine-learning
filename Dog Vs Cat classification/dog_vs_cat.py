# -*- coding: utf-8 -*-
"""dog vs cat.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_dxNi56P59jdGpwI72zE7zCtv5AvWShP

# Information:
SHEIKH ABIR ISLAM
abirraufun1234@gmail.com
"""

#installing kaggle
!pip install kaggle
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

"""using Kaggle API"""

#API
!kaggle competitions download -c dogs-vs-cats

#extract full
from zipfile import ZipFile
file_name = "/content/dogs-vs-cats.zip"
with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print('done')

#extract train
from zipfile import ZipFile
file_name = "/content/train.zip"
with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print('done')

#counting images
import os
path, dirs , files = next(os.walk("/content/train"))
file_count = len(files)
print(file_count)

#printing name if all images
import os
for filename in os.listdir("/content/train"):
  print(filename)

"""Library"""

import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.model_selection import train_test_split
from google.colab.patches import cv2_imshow

"""Display Image"""

#Example of Dog
img = mpimg.imread('/content/train/dog.4072.jpg')
imgplot = plt.imshow(img)
plt.show()
#Example of cat
img = mpimg.imread('/content/train/cat.3598.jpg')
imgplot = plt.imshow(img)
plt.show()

"""Counting DOG and Cat images"""

file_name=os.listdir("/content/train")
dog_count=0
cat_count=0
for i in file_name:
  if i.startswith("dog"):
    dog_count+=1
  else:
    cat_count+=1
print(dog_count)
print(cat_count)

"""# Creat dir and Resizing"""

import os

resized_dir = "/content/Image resized"
if not os.path.exists(resized_dir):
    os.mkdir(resized_dir)

Main_fol= '/content/train'
resize_fol= '/content/Image resized'

for i in range(3000):
  filename= os.listdir(Main_fol)[i]
  img_path= os.path.join(Main_fol, filename)
  img =Image.open(img_path)
  img= img.resize((224,224))
  img=img.convert('RGB')
  newimgpath= os.path.join(resize_fol, filename)
  img.save(newimgpath)

#display resize images
img = mpimg.imread('/content/Image resized/cat.3598.jpg')
imgplot = plt.imshow(img)
plt.show()

"""Creating labels for resized images
---

*   Dog-->1
*   Cat-->0





"""

#assign labels
filename=os.listdir("/content/Image resized/")
labels=[]
for i in range(3000):
  file_name=filename[i]
  label=file_name[0:3] # like dog and cat 3 char
  if label=="dog":
    labels.append(1)
  else:
    labels.append(0)

"""comparing labels"""

print(filename[0:5])
print(len(filename))

print(labels[0:5])
print(len(labels))

"""Counting dogs and cats out of 3000 images"""

values, counts=np.unique(labels, return_counts=True)
print(values)
print(counts)

"""Converting all resize images into numpy arrays"""

import cv2
import glob

image_directory= '/content/Image resized/'
image_extension= ['png', 'jpg', 'jpeg']
files=[]
[files.extend(glob.glob(image_directory + '*.' + e )) for e in image_extension]
dog_cat_img=np.asarray([cv2.imread(file) for file in files])

print(dog_cat_img)

type(dog_cat_img)
print(dog_cat_img.shape)

"""Assigning X and Y"""

X=dog_cat_img
Y=np.asarray(labels)

"""Train test spilit"""

X_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size=0.2, random_state=42)

print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)

"""scaling
* values 0 to 1
"""

#scaling
X_train_scaled=X_train/255
X_test_scaled=X_test/255

print(X_train_scaled)

"""**Using tensorflow mobilenet pretrained model for Transfer learning**
--
**Building NN**
"""

import tensorflow as tf
import tensorflow_hub as hub

mobilenet_model='https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4'
pretrained_model=hub.KerasLayer(mobilenet_model, input_shape=(224,224,3), trainable=False)

import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras import layers

# Load feature extractor
mobilenet_url = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"
feature_extractor_layer = hub.KerasLayer(
    mobilenet_url,
    input_shape=(224, 224, 3),
    trainable=False
)

# Lambda workaround to fix symbolic tensor error
def extract_features(x):
    return feature_extractor_layer(x)

# Build model
inputs = tf.keras.Input(shape=(224, 224, 3))
x = layers.Lambda(extract_features)(inputs)
x = layers.Dense(128, activation='relu')(x)
outputs = layers.Dense(2, activation='softmax')(x)

model = tf.keras.Model(inputs=inputs, outputs=outputs)

# Compile model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

"""# Tranning with Transfer learning"""

history_mobilenet = model.fit(X_train_scaled, Y_train, epochs=10, validation_data=(X_test_scaled, Y_test))

#save the model of TF
model.save('model_mobilenet.h5')

"""**Tranning with CNN**
---
"""

from tensorflow.keras import layers, models

# Build a CNN model
model_cnn = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(2, activation='softmax')  # Output layer with 2 classes (dog or cat)
])

model_cnn.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

# Model summary
model_cnn.summary()

#save the model of CNN
model.save('model_cnn.h5')

# Train the CNN model
history_cnn = model_cnn.fit(X_train_scaled, Y_train, epochs=10, validation_data=(X_test_scaled, Y_test))

"""**Analyze Underfitting/Overfitting**
---
"""

# Plotting training and validation accuracy for CNN
plt.plot(history_cnn.history['accuracy'], label='CNN Training Accuracy')
plt.plot(history_cnn.history['val_accuracy'], label='CNN Validation Accuracy')

# Plotting training and validation accuracy for MobileNet
plt.plot(history_mobilenet.history['accuracy'], label='MobileNet Training Accuracy')
plt.plot(history_mobilenet.history['val_accuracy'], label='MobileNet Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plotting training and validation loss for CNN
plt.plot(history_cnn.history['loss'], label='CNN Training Loss')
plt.plot(history_cnn.history['val_loss'], label='CNN Validation Loss')

# Plotting training and validation loss for MobileNet
plt.plot(history_mobilenet.history['loss'], label='MobileNet Training Loss')
plt.plot(history_mobilenet.history['val_loss'], label='MobileNet Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""**Evaluate Metrics (Accuracy, Precision, Recall, F1 Score)**
---
"""

from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

# Predict on the test set
Y_pred_cnn = model_cnn.predict(X_test_scaled)
Y_pred_cnn = np.argmax(Y_pred_cnn, axis=1)  # Convert to class labels

Y_pred_mobilenet = model.predict(X_test_scaled)
Y_pred_mobilenet = np.argmax(Y_pred_mobilenet, axis=1)  # Convert to class labels

# Calculate metrics for CNN
print("CNN Performance Metrics:")
print(f"Accuracy: {accuracy_score(Y_test, Y_pred_cnn)}")
print(f"Precision: {precision_score(Y_test, Y_pred_cnn)}")
print(f"Recall: {recall_score(Y_test, Y_pred_cnn)}")
print(f"F1 Score: {f1_score(Y_test, Y_pred_cnn)}")

# Calculate metrics for MobileNet
print("MobileNet Performance Metrics:")
print(f"Accuracy: {accuracy_score(Y_test, Y_pred_mobilenet)}")
print(f"Precision: {precision_score(Y_test, Y_pred_mobilenet)}")
print(f"Recall: {recall_score(Y_test, Y_pred_mobilenet)}")
print(f"F1 Score: {f1_score(Y_test, Y_pred_mobilenet)}")

"""**Predictive System**
----
"""

from tensorflow.keras.utils import get_custom_objects
from tensorflow.keras import layers
import tensorflow_hub as hub

# feature extraction function
def extract_features(x):
    return feature_extractor_layer(x)

# custom function
get_custom_objects().update({'extract_features': extract_features})
model.save('model_mobilenet.h5')

# Load models
cnn_model = load_model('model_cnn.h5', custom_objects={'extract_features': extract_features})
tl_model = load_model('model_mobilenet.h5', custom_objects={'extract_features': extract_features})
model.save('model_mobilenet.h5')

# Load the models ensuring the custom function is available
cnn_model = load_model('model_cnn.h5', custom_objects={'extract_features': extract_features})
tl_model = load_model('model_mobilenet.h5', custom_objects={'extract_features': extract_features})

# Get the image path
import_img_path = input('Path of the image to be predicted: ')
input_img = cv2.imread(import_img_path)


if input_img is None:
    print("Error: Image not found. Please check the path.")
else:

    input_img_resize = cv2.resize(input_img, (224, 224))
    input_img_scaled = input_img_resize / 255.0
    input_img_reshape = np.reshape(input_img_scaled, [1, 224, 224, 3])


    cnn_prediction = cnn_model.predict(input_img_reshape)
    tl_prediction = tl_model.predict(input_img_reshape)

    # CNN model
    cnn_confidence = np.max(cnn_prediction)
    cnn_predicted_class = np.argmax(cnn_prediction)

    #Transfer Learning model
    tl_confidence = np.max(tl_prediction)
    tl_predicted_class = np.argmax(tl_prediction)

    # Display CNN model
    print(f"\nCNN Model Prediction: ")
    if cnn_confidence < 0.7:
        print("⚠️ Not confident: Possibly not a cat or dog.")
    else:
        print('✅ CNN Model: The image is a cat' if cnn_predicted_class == 0 else '✅ CNN Model: The image is a dog')
    print(f"CNN Confidence: {cnn_prediction[0]}")

    # Display Transfer Learning model
    print(f"\nTransfer Learning Model Prediction: ")
    if tl_confidence < 0.7:
        print("⚠️ Not confident: Possibly not a cat or dog.")
    else:
        print('✅ Transfer Learning Model: The image is a cat' if tl_predicted_class == 0 else '✅ Transfer Learning Model: The image is a dog')
    print(f"Transfer Learning Confidence: {tl_prediction[0]}")

    # Show the image
    cv2_imshow(input_img)

